{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23161e15-b92f-408f-ba25-86876b4c470f",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77242aa9-32b5-40e8-8a20-993d1d37e37e",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "17c59e0a-087f-4ac4-8344-7c78d0334e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3442db41-5202-4089-a90e-1f15a65ba086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df: pd.DataFrame):\n",
    "    return df.dropna(axis=1)\n",
    "\n",
    "def remove_rows(df: pd.DataFrame):\n",
    "    return df.dropna(axis=0)\n",
    "\n",
    "def use_custom_value(df: pd.DataFrame, fill_value: Union[int, str]):\n",
    "    return df.fillna(value=fill_value)\n",
    "\n",
    "def use_next_value(df: pd.DataFrame):\n",
    "    return df.fillna(method=\"bfill\")\n",
    "\n",
    "def use_prev_value(df: pd.DataFrame):\n",
    "    return df = df.fillna(method=\"ffill\")\n",
    "def clean_data(df: pd.DataFrame, method: str, fill_value: Optional[Union[str, int, float]] = None):\n",
    "    if method == \"remove_columns\":\n",
    "        df = df.dropna(axis=1)\n",
    "    elif method == \"remove_rows\":\n",
    "        df = df.dropna(axis=0)\n",
    "    elif method == \"user_value\":\n",
    "        assert fill_value != None, \"Provide value for replacement!\"\n",
    "        df = df.fillna(value=fill_value)\n",
    "    elif method == \"next\":\n",
    "        df = df.fillna(method=\"bfill\")\n",
    "    elif method == \"previous\":\n",
    "        df = df.fillna(method=\"ffill\")\n",
    "    else:     \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d139255-903d-4b27-a815-276a94a694f5",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f9074e9-b638-4627-9001-20e73fffd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(\n",
    "    df: pd.DataFrame,\n",
    "    test_split: float = 0.1,\n",
    "    target_variable: Optional[Union[int, str]] = None,\n",
    "):\n",
    "    assert test_split < 1\n",
    "    train_split = 1 - test_split\n",
    "    df_sample = df.sample(frac=1, random_state=42)\n",
    "    if target_variable is not None:\n",
    "        grouped_df = df_sample.groupby(target_variable)\n",
    "        arr_list = [np.split(g, [int(train_split * len(g))]) for i, g in grouped_df]\n",
    "        df_train = pd.concat([t[0] for t in arr_list])\n",
    "        df_test = pd.concat([v[1] for v in arr_list])\n",
    "    else:\n",
    "        indices = [int(train_split * len(df))]\n",
    "        df_train, df_test = np.split(df_sample, indices)\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "832e54d4-2505-4afc-a316-e387fd04e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(\n",
    "    df: pd.DataFrame,\n",
    "    target_variable: str,\n",
    "    test_split: float = 0.1,\n",
    "):\n",
    "    assert test_split < 1\n",
    "    train_split = 1 - test_split\n",
    "    train_size = int(np.ceil(train_split * len(df)))\n",
    "    df = df.sort_values(by=target_variable)\n",
    "    df_train = df.iloc[0:train_size, :]\n",
    "    df_test = df.iloc[train_size:, :]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243d905-1d6f-4802-b8a7-98bb4e2b7ff6",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19043792-651e-4158-905b-5e24ef5e63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8\n",
    "\n",
    "\n",
    "def min_max_scaling(x: np.ndarray):\n",
    "    return (x - x.min()) / (np.ptp(x))\n",
    "\n",
    "\n",
    "def max_abs_scaling(x: np.ndarray):\n",
    "    return x / np.max(x, axis=0)\n",
    "\n",
    "\n",
    "def standard_scaling(x: np.ndarray):\n",
    "    return (x - x.mean(axis=0)) / (x.std(axis=0) + eps)\n",
    "\n",
    "\n",
    "def unit_vector_scaling(x: np.ndarray):\n",
    "    return (x.transpose() / np.linalg.norm(x, ord=2, axis=1)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330e886-feac-45db-9d8a-5403f805e7c7",
   "metadata": {},
   "source": [
    "## Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32839633-6c17-41e3-aec1-027f73fdafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    assert len(y_pred) == len(y_true)\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for i in range(len(y_true)):\n",
    "        confusion_matrix[y_pred[i], y_true[i]] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c51d4dce-8202-4161-9079-76c07f34736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true: np.ndarray, y_pred: np.ndarray, average: str = \"micro\"):\n",
    "    precision = 0\n",
    "    confusion_matrix = generate_confusion_matrix(y_true, y_pred)\n",
    "    if average == \"macro\":\n",
    "        score = 0\n",
    "        for i in range(len(confusion_matrix)):\n",
    "            score += confusion_matrix[i, i] / np.sum(confusion_matrix[i, :])\n",
    "        precision = score / len(confusion_matrix)\n",
    "    elif average == \"micro\":\n",
    "        TP = np.trace(confusion_matrix)\n",
    "        precision = TP / np.sum(confusion_matrix)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true: np.ndarray, y_pred: np.ndarray, average: str = \"micro\"):\n",
    "    precision = 0\n",
    "    confusion_matrix = generate_confusion_matrix(y_true, y_pred)\n",
    "    if average == \"macro\":\n",
    "        score = 0\n",
    "        for i in range(len(confusion_matrix)):\n",
    "            score += confusion_matrix[i, i] / np.sum(confusion_matrix[:, i])\n",
    "        precision = score / len(confusion_matrix)\n",
    "    elif average == \"micro\":\n",
    "        TP = np.trace(confusion_matrix)\n",
    "        precision = TP / np.sum(confusion_matrix)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7c1f2ad-ac44-44ca-bda4-a59a0198b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.square(np.subtract(y_true, y_pred)).mean()\n",
    "\n",
    "\n",
    "def RMSE(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.sqrt(MSE(y_true, y_pred))\n",
    "\n",
    "\n",
    "def MAE(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.abs(np.subtract(y_true, y_pred)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
